# ğŸ§  Neural Networks from Scratch with Python & NumPy

This repository contains my implementation of neural networks **from scratch** using only **Python** and **NumPy**, based on the excellent [@Neural Networks from Scratch](https://youtube.com/playlist?list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3&si=zHnjIBpu71T853N5) playlist by [@sentdex](https://github.com/Sentdex/NNfSiX/tree/master/Python).

---

## ğŸ“š What Youâ€™ll Find Here

This repo includes:

- âœ… Forward propagation logic
- âœ… Backpropagation and gradient calculations
- âœ… Fully connected layers (`Dense` layers)
- âœ… Activation functions: ReLU, Softmax
- âœ… Loss functions: Categorical Crossentropy, MSE
- âœ… Optimizers: SGD, Adam
- âœ… Complete training loop
- âœ… Toy dataset training examples (spiral, classification tasks)
- âœ… Modular and well-commented code

---

## ğŸ§  Core Concepts Learned

- Neural network architecture
- Matrix/vector operations with NumPy
- Derivatives and gradients
- Building loss and activation functions manually
- Optimization from scratch
- Debugging and improving training performance

---

## ğŸš€ Getting Started

### ğŸ”§ Prerequisites

- Python 3.7+
- NumPy

```bash
pip install numpy
````

## ğŸ¤ Acknowledgements

Huge thanks to [@sentdex](https://github.com/Sentdex/NNfSiX/tree/master/Python) for the detailed and insightful tutorial series. This project helped me build intuition behind how neural networks actually work at the core level.

