# 🧠 Neural Networks from Scratch with Python & NumPy

This repository contains my hands-on implementation of **neural networks from scratch** using only **Python** and **NumPy**, following the [Neural Networks from Scratch](https://youtube.com/playlist?list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3&si=zHnjIBpu71T853N5) series by [@sentdex](https://github.com/Sentdex/NNfSiX/tree/master/Python).

---


## ✅ Features Implemented

- 🧠 Forward propagation
- 🧮 Manual dot product and matrix operations
- 🔁 Multiple dense layers (fully connected)
- ⚙️ Activation functions: ReLU, Softmax
- ❌ Loss functions: Categorical Crossentropy
- 🧠 From scalar neuron to full multi-layer network

---

## 💡 Concepts Covered

- Building blocks of neural networks
- Manual forward propagation using NumPy
- Designing layers and activations
- Understanding loss functions deeply
- Step-by-step debugging and testing

---

## 🚀 Getting Started

### 📦 Prerequisites

- Python 3.7 or higher
- NumPy

```bash
pip install numpy
````

Then run any script, for example:

```bash
python p005-ReLU-Activation.py
```

---

## 🎓 Acknowledgements

Thanks to [@sentdex](https://github.com/Sentdex/NNfSiX/tree/master/Python) for the incredible educational content that inspired this project. His video series made core neural network concepts much more approachable.

---

## 📌 Note

This repository is educational in purpose and avoids high-level libraries like TensorFlow or PyTorch on purpose — to reinforce foundational understanding.
```
